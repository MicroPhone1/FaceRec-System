{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep The Data\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "folder_name = \"DataSet_Me/person1\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Load the face detector (Haarcascade)\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# Open the video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Counter for the number of images captured\n",
    "img_count = 0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Cannot read frame from the camera\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Draw rectangles around detected faces\n",
    "    for x, y, w, h in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Capture and save the face image in the DataSet_Me folder\n",
    "        face_img = frame[y : y + h, x : x + w]\n",
    "        img_count += 1\n",
    "        img_path = os.path.join(folder_name, f\"face_{img_count}.jpg\")\n",
    "        cv2.imwrite(img_path, face_img)\n",
    "        print(f\"Saved image {img_path}\")\n",
    "\n",
    "    # Display the current frame\n",
    "    cv2.imshow(\"Keeping Data......\", frame)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check file\n",
    "import os\n",
    "\n",
    "data_dir = \"DataSet_Me\"\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"Folder {data_dir} not found\")\n",
    "else:\n",
    "    subfolders = os.listdir(data_dir)\n",
    "    print(f\"Subfolders in {data_dir}: {subfolders}\")\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(data_dir, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            files = os.listdir(subfolder_path)\n",
    "            print(f\"Files in {subfolder_path}: {files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image size\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Path to the data folder\n",
    "train_dir = \"DataSet_Me\"  # Folder containing face data divided into person1 and unknown\n",
    "\n",
    "# Create ImageDataGenerator with data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values to 0-1\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "# Create data generator for training data\n",
    "data_gen = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),  # Define the desired image size\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",  # Binary classification (person1 and unknown)\n",
    ")\n",
    "\n",
    "# Build CNN model\n",
    "model = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(\n",
    "            32, (3, 3), activation=\"relu\", input_shape=(img_height, img_width, 3)\n",
    "        ),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),  # Sigmoid for binary classification\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",  # Binary cross-entropy for binary classification\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(data_gen, epochs=20, steps_per_epoch=data_gen.samples // batch_size)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"face_recognition_model.h5\")\n",
    "\n",
    "print(\"Model trained and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"face_recognition_model.h5\")\n",
    "\n",
    "# Load the face detector (Haarcascade)\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Image parameters (using 128x128 to match the model)\n",
    "img_height, img_width = 128, 128\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Cannot read frame from the camera\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale to speed up face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Crop the face from the frame for prediction\n",
    "        face_img = frame[y : y + h, x : x + w]\n",
    "        face_img = cv2.resize(\n",
    "            face_img, (img_height, img_width)\n",
    "        )  # Resize the image to fit the model\n",
    "        face_img = np.expand_dims(face_img, axis=0)  # Add batch dimension\n",
    "        face_img = face_img / 255.0  # Normalize\n",
    "\n",
    "        # Use the model to predict if the face is known or unknown\n",
    "        prediction = model.predict(face_img)\n",
    "\n",
    "        # Display the result of the prediction\n",
    "        if prediction[0] > 0.1:\n",
    "            label = \"Known Face\"\n",
    "        else:\n",
    "            label = \"Unknown Face\"\n",
    "\n",
    "        # Put the label on the face\n",
    "        cv2.putText(\n",
    "            frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2\n",
    "        )\n",
    "\n",
    "    # Show the current frame\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"face_recognition_model.h5\")\n",
    "\n",
    "# Load the face detector (Haarcascade)\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Image parameters\n",
    "img_height, img_width = 128, 128\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Cannot read frame from the camera\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale to speed up face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    known_face_detected = False\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Crop the face from the frame for prediction\n",
    "        face_img = frame[y : y + h, x : x + w]\n",
    "        face_img = cv2.resize(\n",
    "            face_img, (img_height, img_width)\n",
    "        )  # Resize the image to fit the model\n",
    "        face_img = np.expand_dims(face_img, axis=0)  # Add batch dimension\n",
    "        face_img = face_img / 255.0  # Normalize\n",
    "\n",
    "        # Use the model to predict if the face is known or unknown\n",
    "        prediction = model.predict(face_img)\n",
    "\n",
    "        # Display the result of the prediction\n",
    "        if prediction[0] > 0.5:  # Adjust threshold as needed\n",
    "            label = \"Known Face\"\n",
    "            known_face_detected = True\n",
    "        else:\n",
    "            label = \"Unknown Face\"\n",
    "\n",
    "        # Put the label on the face\n",
    "        cv2.putText(\n",
    "            frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2\n",
    "        )\n",
    "\n",
    "    # Draw a circle at the top-right corner of the window\n",
    "    if known_face_detected:\n",
    "        cv2.circle(\n",
    "            frame, (frame.shape[1] - 30, 30), 20, (0, 255, 0), -1\n",
    "        )  # Green circle\n",
    "    else:\n",
    "        cv2.circle(frame, (frame.shape[1] - 30, 30), 20, (0, 0, 255), -1)  # Red circle\n",
    "\n",
    "    # Show the current frame\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
